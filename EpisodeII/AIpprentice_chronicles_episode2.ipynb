{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6372fa6",
   "metadata": {},
   "source": [
    "# **Episode II: Attack of the YOLOv5**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b188742",
   "metadata": {},
   "source": [
    "## 0. Preambule \n",
    "\n",
    "here we choose to work with YOLOv5 with a docker container, to pull the image and start a container use the following command\n",
    "```\n",
    "t=ultralytics/yolov5:latest && docker pull $t && docker run -it --ipc=host --gpus all -p 8888:8888 -v $PWD:/usr/src/app/AIpprenticeChronicles $t\n",
    "```\n",
    "then start jupyter from the container using the command\n",
    "```\n",
    "jupyter notebook --ip 0.0.0.0 --no-browser --port=8888 --allow-root\n",
    "\n",
    "```\n",
    "and open the notebook `AIpprentice_chronicles_episode2.ipynb`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3678d7d0",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "YOLOv5 is a state-of-the-art object detection model known for its speed and accuracy. Built upon the You Only Look Once (YOLO) concept, YOLOv5 introduces a streamlined architecture consisting of a backbone network, neck network, and detection head. It is trained on large-scale datasets like COCO and utilizes anchor boxes for bounding box predictions. YOLOv5 leverages advanced techniques such as multi-scale training, data augmentation, and focal loss to improve object detection performance. With its efficient architecture and comprehensive training pipeline, YOLOv5 has become a popular choice for real-time object detection tasks.\n",
    "\n",
    "Transfer learning is a powerful technique in deep learning where a pre-trained model, typically trained on a large-scale dataset, is utilized as a starting point for a new task or dataset. By leveraging the knowledge learned from the pre-training phase, transfer learning enables the transfer of valuable representations and learned features to the new task.\n",
    "\n",
    "This notebook largely borrows from the nice article [YOLOv5 Transfer Learning In Simple Steps Without Losing Your Mind](https://kikaben.com/yolov5-transfer-learning-dogs-cats/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6714c6a6",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Using the scripts implemented in the first episode we generate a dataset containing 1000 labelled images and display the first 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b411b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "from PIL import Image, ImageDraw\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# Define a dictionary to store information about different objects\n",
    "objects = {\n",
    "    0: {'name': 'Sun', 'file': 'sun.png', 'code': 'SU'},\n",
    "    1: {'name': 'Earth', 'file': 'earth.png', 'code': 'EA'},\n",
    "    2: {'name': 'Mars', 'file': 'mars.png', 'code': 'MA'},\n",
    "    3: {'name': 'Venus', 'file': 'venus.png', 'code': 'VE'},\n",
    "    4: {'name': 'Jupiter', 'file': 'jupiter.png', 'code': 'JU'},\n",
    "    5: {'name': 'Mercury', 'file': 'mercury.png', 'code': 'ME'},\n",
    "    6: {'name': 'Saturn', 'file': 'saturn2.png', 'code': 'SA'},\n",
    "    7: {'name': 'Neptune', 'file': 'neptune.png', 'code': 'NE'},\n",
    "    8: {'name': 'Uranus', 'file': 'uranus.png', 'code': 'UR'},\n",
    "    9: {'name': 'Asteroid', 'file': 'asteroid.png', 'code': 'AS'},\n",
    "    10: {'name': 'Black Hole', 'file': 'black-hole.png', 'code': 'BL'},\n",
    "    11: {'name': 'Star Destroyer', 'file': 'star-destroyer.png', 'code': 'ST'}\n",
    "}\n",
    "\n",
    "# Get the total number of objects\n",
    "n_objects = len(objects)\n",
    "\n",
    "# Define a list to store background images\n",
    "bg = []\n",
    "bg.append(Image.open(r\"../img/background/bg1.jpg\"))\n",
    "bg.append(Image.open(r\"../img/background/bg2.jpg\"))\n",
    "bg.append(Image.open(r\"../img/background/bg3.jpg\"))\n",
    "\n",
    "# Set the directory path for object images\n",
    "im_dir = '../img/objects'\n",
    "\n",
    "# Loop through each object in the objects dictionary\n",
    "for class_id, values in objects.items():\n",
    "    # Open and convert the image file for the current planet\n",
    "    png_file = Image.open(os.path.join(im_dir, values['file'])).convert('RGBA')\n",
    "    \n",
    "    # Crop the image to a square shape using the maximum dimension\n",
    "    png_file = png_file.crop((0, 0, np.max(png_file.size), np.max(png_file.size)))\n",
    "    \n",
    "    # Store the processed image in the objects dictionary\n",
    "    objects[class_id]['image'] = png_file\n",
    "    \n",
    "# Function to get a random background image and crop it\n",
    "def get_bg(bg): \n",
    "    id_bg = np.random.randint(0, 3)  # Randomly select a background image index\n",
    "    bg_tmp = bg[id_bg]  # Get the selected background image\n",
    "    (w, h) = bg_tmp.size  # Get the dimensions of the background image\n",
    "    x1 = np.random.randint(0, w - bg_size)  # Randomly choose x-coordinate for cropping\n",
    "    y1 = np.random.randint(0, h - bg_size)  # Randomly choose y-coordinate for cropping\n",
    "    bg_tmp = bg_tmp.crop((x1, y1, x1 + bg_size, y1 + bg_size))  # Crop the background image\n",
    "    return bg_tmp\n",
    "\n",
    "# Function to overlay a planet onto the background image\n",
    "def put_object(obj, bg_tmp):\n",
    "    h = obj.size[0]  # Get the size of the object image\n",
    "    if h >= bg_size:\n",
    "        scale = 0.4 * np.random.random() + 0.1  # Randomly choose a scale for large object\n",
    "    else:\n",
    "        scale = 0.7 * np.random.random() + 0.1  # Randomly choose a scale for small object\n",
    "    h = np.int32(scale * h)  # Calculate the new size of the object image based on the scale\n",
    "    p = obj.resize((h, h))  # Resize the object image\n",
    "    h_bg = bg_tmp.size[0]  # Get the size of the background image\n",
    "    x = np.random.randint(0, h_bg - h)  # Randomly choose x-coordinate for placing the object\n",
    "    y = np.random.randint(0, h_bg - h)  # Randomly choose y-coordinate for placing the object\n",
    "    bg_tmp.paste(p, (x, y), mask=p)  # Paste the object onto the background image\n",
    "    return bg_tmp, x, y, h\n",
    "\n",
    "# Function to create a single example for the dataset\n",
    "def create_example():\n",
    "    class_id = np.random.randint(0, n_objects)  # Randomly choose a class ID\n",
    "    bg_tmp = get_bg(bg)  # Get a random background image\n",
    "    plan_im = objects[class_id]['image']  # Get the image of the chosen class\n",
    "    img, x, y, h = put_object(plan_im, bg_tmp)  # Overlay the object on the background\n",
    "    img = img.resize((im_size, im_size))  # Resize the image to the desired size\n",
    "    x1 = np.float32(x) / bg_size  # Normalize x-coordinate of the object's position\n",
    "    y1 = np.float32(y) / bg_size  # Normalize y-coordinate of the object's position\n",
    "    h = np.float32(h) / bg_size  # Normalize size of the object\n",
    "    return img, class_id, x1, y1, h\n",
    "\n",
    "# Function to create the dataset\n",
    "def create_dataset(set_size):\n",
    "    dataset = []\n",
    "    for i in tqdm(range(set_size)):\n",
    "        image, class_id, x1, y1, h = create_example()\n",
    "        dataset.append([image, class_id, x1, y1, h])\n",
    "    return dataset\n",
    "\n",
    "bg_size = 800  # Size of the background image\n",
    "im_size = 144  # Size of the resized images\n",
    "\n",
    "print('Generating training set...')\n",
    "dataset = create_dataset(1000)  # Create a dataset of 1000 examples\n",
    "\n",
    "# display first 100 images\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        plt.subplot(10,10,10*i+j+1)\n",
    "        plt.imshow(dataset[10*i+j][0])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8d49a8a",
   "metadata": {},
   "source": [
    "## 3. Prepare for YOLO transfer\n",
    "\n",
    "Here we prepare the dataset for the transfer to YOLOv5:\n",
    " - in the first cell we name and save the images into the `images` folder and produce the corresponding `txt` file containing labels, ie class id and bounding box characteristics\n",
    " - in the subsequent cells the images and labels sets are split and placed in train/val/test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_yolo(dataset):\n",
    "    #for i,data in enumerate(dataset):\n",
    "    print(\"Prepare the dataset for the transfer to YOLOv5\")\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        data = dataset[i]\n",
    "        data[0].save(f'data/images/{i:05d}.png')\n",
    "        c,x1,y1,h = data[1:]\n",
    "        classname=objects[c]['name']\n",
    "        #print(classname)\n",
    "        tmp = np.array([c,x1+h/2,y1+h/2,h,h])\n",
    "        np.savetxt(f'data/labels/{i:05d}.txt',tmp.reshape([1,5]),fmt='%d %1.4f %1.4f %1.4f %1.4f')\n",
    "        \n",
    "\n",
    "# Create a folder structure for YOLOv5 training\n",
    "if not os.path.exists('data'):\n",
    "    for folder in ['images', 'labels']:\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            os.makedirs(f'data/{folder}/{split}')\n",
    "dataset_to_yolo(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)\n",
    "index = np.arange(len(dataset))\n",
    "np.random.shuffle(index)\n",
    "\n",
    "list_files=glob.glob(\"data/images/*.png\") \n",
    "list_files.sort()\n",
    "#print(list_files)\n",
    "\n",
    "array_files=np.array(list_files)\n",
    "np.random.shuffle(array_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db971a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Split and move the images and files in train/test/val folders\")\n",
    "\n",
    "train_size = int(len(array_files)*0.7)\n",
    "val_size=int(len(array_files)*0.15)\n",
    "\n",
    "for i, image_path in enumerate(array_files):\n",
    "    label_path = image_path.replace('.png', '.txt').replace('images','labels')\n",
    "        \n",
    "    # Split into train, val, or test\n",
    "    if i < train_size:\n",
    "        split = 'train'\n",
    "    elif i < train_size + val_size:\n",
    "        split = 'val'\n",
    "    else:\n",
    "        split = 'test'\n",
    "   \n",
    "    image_name=image_path.split('/')[-1]\n",
    "    \n",
    "    target_image_name = f'data/images/{split}/{image_name}'\n",
    "    target_label_name = f'data/labels/{split}/{image_name.replace(\"png\",\"txt\")}'\n",
    "    \n",
    "    shutil.copy(image_path, target_image_name)\n",
    "    shutil.copy(label_path, target_label_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbdead49",
   "metadata": {},
   "source": [
    "## 4. run YOLOv5 transfer script\n",
    "\n",
    "Once preprocessing is done, transfer learning and prediction can be performed using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a497c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python /usr/src/app/train.py --data spacequest.yaml --weights yolov5s.pt --epochs 20 --batch 4 --freeze 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "457b0798",
   "metadata": {},
   "source": [
    "Validation examples can be found in the `runs/train/exp/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"../../runs/train/exp/val_batch2_pred.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "998930e1",
   "metadata": {},
   "source": [
    "Finally we generate a new example and apply detection with and without transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d3027",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 400\n",
    "image, class_id, x1, y1, h = create_example()\n",
    "image.save(\"example.png\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac02ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /usr/src/app/detect.py --data spacequest.yaml --weights /usr/src/app/runs/train/exp/weights/best.pt --source example.png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0600cb2b",
   "metadata": {},
   "source": [
    "with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dipslay the result of the detection you may have to adapt \n",
    "# the file path to match the output of the previous cell\n",
    "Image.open(\"../../runs/detect/exp9/example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beecd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /usr/src/app/detect.py --data spacequest.yaml --weights yolov5s.pt --source example.png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65cb8951",
   "metadata": {},
   "source": [
    "without transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921acf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"../../runs/detect/exp/example.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
